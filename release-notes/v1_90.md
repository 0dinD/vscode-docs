---
Order: 99
TOCTitle: May 2024
PageTitle: Visual Studio Code May 2024
MetaDescription: Learn what is new in the Visual Studio Code May 2024 Release (1.90)
MetaSocialImage: 1_90/release-highlights.png
Date: 2024-6-6
DownloadVersion: 1.90.0
---
# May 2024 (version 1.90)

<!-- DOWNLOAD_LINKS_PLACEHOLDER -->

---

Welcome to the May 2024 release of Visual Studio Code. There are many updates in this version that we hope you'll like, some of the key highlights include:

* Highlight 1 goes here
* Highlight 2 goes here

>If you'd like to read these release notes online, go to [Updates](https://code.visualstudio.com/updates) on [code.visualstudio.com](https://code.visualstudio.com).
**Insiders:** Want to try new features as soon as possible? You can download the nightly [Insiders](https://code.visualstudio.com/insiders) build and try the latest updates as soon as they are available.

## Accessibility

### Set keybindings from within the accessibility help dialog

Accessibility help dialogs provide users with an overview of important commands that can be taken for a feature or view. When a command lacks a keybinding assignment, users can configure it from within the help dialog with `kb(editor.action.accessibilityHelpConfigureKeybindings)`.

### Experimental signal delay settings

The setting <code codesetting="accessibility.signalOptions.delays">Signal options delays</code> can be used to customize the debouncing time for various accessibility signals when <code codesetting="accessibility.signalOptions.debouncePositionChanges">Debounce position changes</code> is enabled.


## Workbench


## Editor


## Source Control


## Terminal

### ‚ö†Ô∏è Removal of the canvas renderer

The canvas renderer was deprecated in v1.89 and is now removed completely. What this means is that on the small number of machines that do not support webgl2, the terminal will now use the DOM-based renderer. You can read more about GPU acceleration in the [terminal documentation](https://code.visualstudio.com/docs/terminal/appearance#_gpu-acceleration).

### Rescaling overlapping glyph in the terminal

The setting <code codesetting="terminal.integrated.rescaleOverlappingGlyphs">terminal.integrated.rescaleOverlappingGlyphs</code> that was introduced as a preview feature in v1.88 is now enabled by default. This feature which rescales glyphs that overlap following cells intended to cover ambiguous width characters, which might have font glyphs that don't match what the backing pty/unicode version thinks it is. For example, in most fonts the roman numeral unicode characters (`U+2160+`) typically takes up multiple cells, so they are rescaled horizontally when this setting is enabled.

Without rescaling:

![Before the glyphs for ‚Öß and ‚Ö´ depending on the font would always overlap the following cells](images/1_88/terminal-glyphs-before.png)

With rescaling:

![After the glyphs for ‚Öß and ‚Ö´ depending on the font are rescaled horizontally to fit a single cell](images/1_88/terminal-glyphs-after.png)

## Tasks


## Debug


## Testing


## Languages


## Remote Development

The [Remote Development extensions](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack), allow you to use a [Dev Container](https://code.visualstudio.com/docs/devcontainers/containers), remote machine via SSH or [Remote Tunnels](https://code.visualstudio.com/docs/remote/tunnels), or the [Windows Subsystem for Linux](https://learn.microsoft.com/windows/wsl) (WSL) as a full-featured development environment.

Highlights include:

- TODO: add remote highlights here

You can learn more about these features in the [Remote Development release notes](https://github.com/microsoft/vscode-docs/blob/main/remote-release-notes/v1_90.md).

## Contributions to extensions

### GitHub Copilot

#### Attach context to chat

You can now attach context to chat such as files and workspace symbols. In the panel chat input, click on the üìé icon or type `kb(workbench.action.chat.attachContext)` to choose from available context types. You can use the right arrow key to quickly attach context in the background while keeping the picker open. When you're in the editor, you can also right click on a selection and choose **Copilot > Add Selection to Chat**.

<video src="images/1_90/chat-context-attachments.mp4" title="Attach context to chat" autoplay loop controls muted></video>

#### Ask questions using Bing search and enterprise knowledge bases

[GitHub Copilot Enterprise](https://docs.github.com/en/enterprise-cloud@latest/copilot/github-copilot-enterprise/overview/about-github-copilot-enterprise) users in VS Code can now ask questions that are enriched with context from web results and your enterprise's [knowledge bases](https://docs.github.com/en/enterprise-cloud@latest/copilot/github-copilot-enterprise/copilot-chat-in-github/managing-copilot-knowledge-bases).

To try out this functionality, install the latest pre-release of Copilot Chat. In the Chat view, you can then ask questions like `@github What is the latest LTS of Node.js? #web` to take advantage of web search. Any search results referenced by Copilot will be displayed in the `Used References` section of the chat response.

![Web search results in Copilot Chat](images/1_90/copilot-enterprise-bing-search.png)

You can also ask questions about your enterprise's knowledge bases, which are collections of Markdown repositories containing documentation, directly from VS Code. Simply type `@github #kb` to pick from the knowledge bases available to you. Similarly, any knowledge base snippets referenced by Copilot are displayed in the `Used References` section of the chat response.

This enables Copilot Enterprise users to combine search results and internal documentation with editor context using existing chat variables like `#file` and `#selection`. Please try it out and share your feedback with us at https://github.com/microsoft/vscode-copilot-release!

#### IntelliSense in chat code blocks

<!-- TODO: mjbvz -->

#### More links chat responses

<!-- TODO: mjbvz -->

#### Roam active chat requests from inline to panel chat

Any request that is completed or still active can now be moved from inline chat to panel chat. This allows to clean up inline chat and move conversations to a more persistent place. To move a request select the chat icon that follows in the input box.

### Python

### GitHub Pull Requests and Issues

### VS Code Speech

We added support for text-to-speech capabilities to the [VS Code Speech](https://marketplace.visualstudio.com/items?itemName=ms-vscode.vscode-speech) extension. A new setting <code codesetting="accessibility.voice.autoSynthesize">accessibility.voice.autoSynthesize</code> can be enabled to automatically read out aloud Copilot Chat responses when voice was used as input:

<video src="images/1_90/text-to-speech.mp4" title="Text to Speech in Copilot Chat" autoplay loop controls muted></video>

Notice how the microphone icon in the input field changes to an icon indicating that text is read out aloud. Clicking that icon will stop the synthesis, or you can use the new `kb(workbench.action.speech.stopReadAloud)` command.

Each Chat response shows a new speaker icon so that you can selectively read out a response aloud:

![Text to Speech for a Chat Response](images/1_90/text-to-speech.png)

You can change the language used for reading aloud via the existing <code codesetting="accessibility.voice.speechLanguage">accessibility.voice.speechLanguage</code> setting.

## Preview Features

### VS Code-native intellisense for PowerShell

The main change to this feature apart from reliability improvements in this release are:

- `terminal.integrated.shellIntegration.suggestEnabled` has been changed to `terminal.integrated.suggest.enabled`
- The new `terminal.integrated.suggest.quickSuggestions` controls whether suggestions are shown when you type after whitespace
- The new `terminal.integrated.suggest.suggestOnTriggerCharacters` controls whether suggestions are shown when you type `/`, `\` or `-`

### TypeScript 5.5

<!-- TODO: mjbvz -->

### TypeScript Paste With imports

<!-- TODO: mjbvz -->

## API

### Chat and Language Model API

We have finalized APIs that allow extensions to participate in chat and to access language models.

> ‚ÄºÔ∏è Please note that these APIs are finalized but currently only available in VS Code Insiders ‚ÄºÔ∏è

#### Chat Participants

#### Language Model

The language model API allows to access Copilot's chat models, like gpt-3.5 and gpt-4. This can be used for chat participants but also to enrich other features. The API is built around [`LanguageModelChat`](https://github.com/microsoft/vscode/blob/54dd0ecc653b89e6032369c6f4b1808bc8e37ec5/src/vscode-dts/vscode.d.ts#L19032)-objects which are used for chat requests and for counting tokens.

The only way to access chat objects is the `vscode.lm.selectChatModels`-function. It accepts a selector to narrow down on different properties of chat models like vendor, family, version, or identifier. The values are relatively free-form and must be looked up in the documentation of the extensions providing them. Today, only Copilot Chat contributes chat models. It uses the `copilot`-vendor and current families are `gpt-3.5-turbo` and `gpt-4` but are subject to change.

The snippet below will select all chat models from the `copilot`-vendor:

```ts
const models = await vscode.lm.selectChatModels({
	vendor: 'copilot',
});

if(models.length === 0) {
	// no models available
	return;
}
```

Two things are very **important** when callng `selectChatModels`

1. The function will return an _empty_ array if no models are available and extensions must handle this case
2. Copilot's chat models require consent from the user before an extension my use them. Consent is implemented as auth-dialog and because of that `selectChatModels` should be called as part of a user-initiated action like a command and not "out of the blue".


With a chat object at hand, extensions can now use it to send chat requests. The snippet below does that and shows how to process the response stream.

```ts
// take the first model and say "Hello"
const [chat] = models;
const messages = [vscode.LanguageModelChatMessage.User('Hello')];
const response = await chat.sendRequest(messages);

// the response is always an async iterable that can be consumed with for-await
for await (const part of response.text) {
	console.log(part)
}
```

This is the gist of the language model API. Head over to https://github.com/microsoft/vscode-extension-samples/tree/main/chat-sample for a more complete example. Stay tuned for more samples, documentation, and further extensions of the API.

## Proposed APIs

### Embeddings API

<!-- TODO@jrieken -->

## Engineering

### Tracking memory efficiency on startup

We measure startup performance of VS Code insiders every day across Windows, macOS and Linux. Our main interest is how fast startup is until a text file is opened.

This month we added another metric that we plan to improve to make startup even faster: how much memory do we consume and how much of that memory ends up being garbage collected by V8. If we can bring that number down, startup time will be less affected by V8 garbage collection runs.

![Memory Efficiency](images/1_90/memory-perf.png)

## Notable fixes

* [212386](https://github.com/microsoft/vscode/issues/212386) Local history: does not preserve entries from previously deleted file
* [213645](https://github.com/microsoft/vscode/issues/213645) Aux window does not work in Firefox

## Thank you

Last but certainly not least, a big _**Thank You**_ to the contributors of VS Code.

### Issue tracking

Contributions to our issue tracking:

* [@gjsjohnmurray (John Murray)](https://github.com/gjsjohnmurray)
* [@IllusionMH (Andrii Dieiev)](https://github.com/IllusionMH)
* [@RedCMD (RedCMD)](https://github.com/RedCMD)
* [@starball5 (starball)](https://github.com/starball5)
* [@ArturoDent (ArturoDent)](https://github.com/ArturoDent)

### Pull requests


<a id="scroll-to-top" role="button" title="Scroll to top" aria-label="scroll to top" href="#"><span class="icon"></span></a>
<link rel="stylesheet" type="text/css" href="css/inproduct_releasenotes.css"/>
